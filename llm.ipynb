{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb18c9f6-4926-4863-8d71-a07e168e912e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in e:\\supporting tools\\python\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in e:\\supporting tools\\python\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in e:\\supporting tools\\python\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in e:\\supporting tools\\python\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\supporting tools\\python\\lib\\site-packages (from torch) (4.12.1)\n",
      "Requirement already satisfied: networkx in e:\\supporting tools\\python\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\supporting tools\\python\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in e:\\supporting tools\\python\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in e:\\supporting tools\\python\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\supporting tools\\python\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\supporting tools\\python\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in e:\\supporting tools\\python\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\supporting tools\\python\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\supporting tools\\python\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0\n",
      "    Uninstalling torchvision-0.21.0:\n",
      "      Successfully uninstalled torchvision-0.21.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.6.0\n",
      "    Uninstalling torchaudio-2.6.0:\n",
      "      Successfully uninstalled torchaudio-2.6.0\n",
      "Successfully installed torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (E:\\Supporting Tools\\Python\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47dbb30-ee8e-4d18-b90a-f0d134fce10f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\supporting tools\\python\\lib\\site-packages (1.5.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\supporting tools\\python\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\supporting tools\\python\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\supporting tools\\python\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\supporting tools\\python\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60463399-94af-4621-bbc5-914b5a0fddbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in e:\\supporting tools\\python\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\supporting tools\\python\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in e:\\supporting tools\\python\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\supporting tools\\python\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.12-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in e:\\supporting tools\\python\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\supporting tools\\python\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\supporting tools\\python\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\supporting tools\\python\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\supporting tools\\python\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\supporting tools\\python\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\supporting tools\\python\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\supporting tools\\python\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: colorama in e:\\supporting tools\\python\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\supporting tools\\python\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\supporting tools\\python\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\supporting tools\\python\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\supporting tools\\python\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading aiohttp-3.11.12-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-19.0.0-cp312-cp312-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/25.2 MB 5.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.4/25.2 MB 6.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.7/25.2 MB 5.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.2/25.2 MB 6.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.3/25.2 MB 6.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.3/25.2 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.7/25.2 MB 5.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.2/25.2 MB 6.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.6/25.2 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.9/25.2 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.3/25.2 MB 7.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.8/25.2 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.2/25.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.0/25.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.6/25.2 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.2 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Installing collected packages: xxhash, tqdm, pyarrow, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 datasets-3.3.1 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.28.1 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-19.0.0 tqdm-4.67.1 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb60837-096a-45a4-a913-628b2a182250",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed903b307dc94c05920cfdf9f61a0ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Supporting Tools\\Python\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shreeya Kannan\\.cache\\huggingface\\hub\\datasets--roneneldan--TinyStories. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fb3137f6a64356beed9d83e1dd520e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00004-2d5a1467fff1081b.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17dc9048b22422c85fbe7a0eb041901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00004-5852b56a2bd28fd9.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80b5f0c4007409fa4f838e9bc5c661d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00004-a26307300439e943.parquet:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed48011cc75e46f8a4b954aba8eff978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00003-of-00004-d243063613e5a057.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990e1dcdfda34a3e8dd56bc922a9499d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-869c898b519ad725.parquet:   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b298674b8c2a4551822c43765e84b2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0061131bc53e4f1da127f4c29a258c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the TinyStories dataset\n",
    "ds = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6028558f-6324-4fab-a813-72b7628642f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Supporting Tools\\Python\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 123\u001b[0m\n\u001b[0;32m    120\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    121\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 123\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")\n",
    "\n",
    "# Custom Tokenizer\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, texts, max_vocab=10000):\n",
    "        self.word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "        self.idx2word = {0: \"<PAD>\", 1: \"<UNK>\"}\n",
    "        self.build_vocab(texts, max_vocab)\n",
    "\n",
    "    def build_vocab(self, texts, max_vocab):\n",
    "        word_freq = {}\n",
    "        for text in texts:\n",
    "            for word in text.split():\n",
    "                word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        \n",
    "        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "        for word, _ in sorted_words[:max_vocab-2]:\n",
    "            self.word2idx[word] = len(self.word2idx)\n",
    "            self.idx2word[len(self.idx2word)] = word\n",
    "\n",
    "    def encode(self, text, max_length):\n",
    "        tokens = [self.word2idx.get(word, 1) for word in text.split()]\n",
    "        return tokens[:max_length] + [0] * (max_length - len(tokens))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return \" \".join([self.idx2word.get(token, \"<UNK>\") for token in tokens])\n",
    "\n",
    "# Custom Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]['text']\n",
    "        encoded = self.tokenizer.encode(text, self.max_length)\n",
    "        return torch.tensor(encoded)\n",
    "\n",
    "# Transformer Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "VOCAB_SIZE = 10000\n",
    "D_MODEL = 256\n",
    "NHEAD = 8\n",
    "NUM_LAYERS = 4\n",
    "EPOCHS = 5\n",
    "\n",
    "# Initialize tokenizer and datasets\n",
    "tokenizer = SimpleTokenizer(train_dataset['text'], VOCAB_SIZE)\n",
    "train_data = TextDataset(train_dataset, tokenizer, MAX_LENGTH)\n",
    "valid_data = TextDataset(valid_dataset, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerModel(VOCAB_SIZE, D_MODEL, NHEAD, NUM_LAYERS).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_seq = batch[:, :-1].to(device)\n",
    "        target_seq = batch[:, 1:].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output.view(-1, VOCAB_SIZE), target_seq.contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        for batch in valid_loader:\n",
    "            input_seq = batch[:, :-1].to(device)\n",
    "            target_seq = batch[:, 1:].to(device)\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.view(-1, VOCAB_SIZE), target_seq.contiguous().view(-1))\n",
    "            total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Generate text\n",
    "def generate_text(model, tokenizer, seed_text, max_length=50):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(seed_text, max_length)\n",
    "    input_seq = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output = model(input_seq)\n",
    "            next_token = output[0, -1, :].argmax().item()\n",
    "            input_seq = torch.cat([input_seq, torch.tensor([[next_token]]).to(device)], dim=1)\n",
    "            if next_token == 0:  # <PAD> token\n",
    "                break\n",
    "    \n",
    "    return tokenizer.decode(input_seq.squeeze().tolist())\n",
    "\n",
    "# Generate sample text\n",
    "seed_text = \"Once upon a time\"\n",
    "generated_text = generate_text(model, tokenizer, seed_text)\n",
    "print(f\"Generated text: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2d709-7da0-439f-a273-b6e6093d9cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
